---
title: "NTL LTER Data Cleaning"
author: "Maxwell Pepperdine"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

## Background 

This script is used to clean the North Temperate Lakes Long Term Ecological Research (NTL LTER) data, consisting of the following two datasets: the daily meteorological data (`ntl20_v13.csv`) and the ice duration data (`ntl33_v12.csv`). Our goal is to both clean the datasets and wrangle them into a format where they can be joined by a primary/foreign key relationship, so that they can be used in our analysis and ingested into a relational database using `DuckDB`.

## Load packages

```{r}
library(tidyverse)
library(here)
```

## Load data

```{r}
# Madison Wisconsin Daily Meteorological Data 1869 - current
daily_meteor <- read_csv(here("data/discussion_data/daily_meteorological/ntl20_v13.csv"))


# North Temperate Lakes LTER: Ice Duration - Madison Lakes Area 1853 - current
ice_duration <- read_csv(here("data/discussion_data/ntl_ice_duration/ntl33_v12.csv"))
```

## Data cleaning

#### Ice duration data

To align with the data range of the meteorological data, we'll filter the ice duration data to only include records from 1869 to 2023.

Additionally, Lake Wingra (`WI`) is missing a lot of data, so we'll only keep the records from the two lakes that have complete data over this period: Lake Mendota (`ME`) and Lake Monona (`MO`). It's generally preferred to retain as much data as possible, but for this specific database and analysis, we will remove it for consistency and to avoid any potential bias in the analysis.

````{r}
# Check the structure of the ice duration data
glimpse(ice_duration)

# filter the data
ice_duration <- ice_duration %>%
  # keep only data b/w 1869 and 2023 to align with the meteorological data
  filter(year >= 1869 & year <= 2023) %>% 
  # remove the ice duration data from the Wisconsin lakes
  filter(lakeid %in% c("MO", "ME"))
```

```{r}
# save the cleaned ice duration data as a csv
write_csv(ice_duration, here("data/discussion_data/processed/ice_duration_cleaned.csv"), 
          append = FALSE)
```

#### Daily meteorological data

```{r}
# Check the structure of the daily meteorological data
glimpse(daily_meteor)

# change the year4 column name to year to make joining easier
daily_meteor <- daily_meteor %>%
  rename(year = year4)
```

- To make sure the meteorological data is in the same format as the ice duration data, we need to generate a new `year` variable that is the year of the ice season. 
- In the ice duration data, the earliest ice_on to ice_off generally runs from November to April. 
- We need to make a new column (`month`) that extracts the months from the `sampledate` column, and then filter the data to only include records from December to May.
- We can then group the data by year, and calculate the mean of each variable during the "ice season" of each year
- We are only keeping the meteorological data during these defined "ice season" months (Nov-Apr) because the ice duration data is directly representative of these months.

###### Add a month column

Add a new month column and then filter the data to only include records from December to May. This will leave us with daily observations only from the "ice season".

```{r}
# create a new column called month that extracts the month from the sampledate column
daily_meteor <- daily_meteor %>%
  mutate(month = month(sampledate), 
         .before = max_air_temp_adjusted)

# filter the data to only include records from December to May
daily_meteor_iceszn <- daily_meteor %>%
  filter(month >= 11 | month <= 4)

# check all unique values in the month column to QC
unique(daily_meteor_iceszn$month)
```

###### Summarise the data

Now that we have the data filtered to only include records from November to April, we can group the data by year and calculate the mean of each variable during the "ice season" of each year.

```{r}
# group by year and calculate the mean or sum of each variable as appropriate
yearly_meteor_iceszn <- daily_meteor_iceszn %>%
  group_by(year) %>% 
  summarise(
    max_air_temp_adjusted = mean(max_air_temp_adjusted, na.rm = TRUE),
    max_air_temp_raw = mean(max_air_temp_raw, na.rm = TRUE),
    min_air_temp_adjusted = mean(min_air_temp_adjusted, na.rm = TRUE),
    min_air_temp_raw = mean(min_air_temp_raw, na.rm = TRUE),
    avg_air_temp_adjusted = mean(avg_air_temp_adjusted, na.rm = TRUE),
    avg_air_temp_raw = mean(avg_air_temp_raw, na.rm = TRUE),
    range_air_temp_adjusted = mean(range_air_temp_adjusted, na.rm = TRUE),
    precip_raw_mm = sum(precip_raw_mm, na.rm = TRUE),
    snow_raw_cm = sum(snow_raw_cm, na.rm = TRUE),,
    snow_depth_cm = mean(snow_depth_cm, na.rm = TRUE),
  )
```

```{r}
# export the cleaned daily meteorological data as a csv
write_csv(yearly_meteor_iceszn, here("data/discussion_data/processed/yearly_meteor_iceszn.csv"), 
          append = FALSE)
```













